# データの欠損 {#Missing-data}

```{r, out.width=c("50%"), echo=F}
knitr::include_graphics(here::here("images", "missingness.png"))
knitr::include_graphics(here::here("images", "missingness_overview.png"))
```

このページでは以下の内容について説明します：

1)  欠損の評価\
2)  欠損による行のフィルタリング\
3)  時系列による欠損のプロット\
4)  プロットにおける `NA` の処理の仕方\
5)  欠損値の補完：MCAR, MAR, MNAR

<!-- ======================================================= -->

## 準備

### パッケージの読み込み {.unnumbered}

以下のコードは解析に必要なパッケージの読み込みを示しています。このハンドブックでは、**pacman** の `p_load()` を特に使用していますが、パッケージのインストールを必要に応じて行い、[かつ]{.ul}読み込みまで行ってくれます。他にも、**base** R の `library()` を用いてインストールされているパッケージを読み込む方法があります。R のパッケージについてより知りたい場合は、[R の基礎 {#basics}] を参考にしてください。

```{r}
pacman::p_load(
  rio,           # インポート／エクスポート
  tidyverse,     # データの管理と視覚化
  naniar,        # 欠損を評価と視覚化
  mice           # 欠損値の補完
)
```

### データのインポート {.unnumbered}

エボラ流行熱のシミュレーションケースのデータセットをインポートします。同じように行いたい場合、<a href='https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/case_linelists/linelist_cleaned.rds' class='download-button'>クリックして"クリーニングされた（clean）" ラインリストをダウンロードしてください</a> （.rds 形式のファイルです）。**rio** パッケージの関数 `import()` を用いてデータをインポートしてください（.xlsx, .rds, .csv など、様々な形式のファイルをダウンロードすることが出来ますー詳しくは[インポートとエクスポート {#Importing}] のページを参照にしてください。）

```{r, echo=F}
# ラインリストを R にインポートする
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))
```

```{r, eval=F}
# ラインリストをインポートする
linelist <- import("linelist_cleaned.rds")
```

最初の 50 行を以下に示します。

```{r, message=FALSE, echo=F}
# ラインリストのデータをテーブルとして表示する
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

### インポート時における欠損の変換 {.unnumbered}

データをインポートする際に、欠損、と分類されるべき値については少し注意が必要です。例えば、99、999、"Missing"、空欄（""）、または 空のスペースを含むセル（" "） などです。インポートのコマンドと一緒にこれらの値を `NA` （R における欠損値の意味）に変換することが出来ます。\
使用するコマンドがファイルのタイプによって異なるので、詳細については [データの欠損](#import_missing) のインポートのセクションを参考にしてください。

<!-- ======================================================= -->

## R における欠損値

以下では、R における欠損の表示や評価の仕方、また、それに関連するいくつかの値や関数について見ていきたいと思います。

### `NA` {.unnumbered}

R においては、欠損値は特に `NA` という値で表示されます。これは引用符[なし]{.ul}で用いります。"NA" は特殊で、普通の文字値と同じです。

データ内では"99"、"Missing"、または "Unknown" というように欠損が表されていることもあります。また、空の文字値 ""（空欄のように見える）や、スペース " " で表されていることもあります。これらについては、[インポート時に `NA` に変換する](#import_missing) もしくはデータを `na_if()` を用いてクリーニングする必要があります。

データクリーニングにおいて、逆に全ての `NA` を "Missing" に変換したり、`replace_na()` やカテゴリ変数の場合は `fct_explicit_na()` を用いて処理したい場合もあると思います。

### いろいろな `NA` {.unnumbered}

多くの場合は、`NA` が欠損値を示し、それで全てがうまくいきます。しかし、オブジェクトのクラス（文字値、数値、など）によって[異なる]{.ul} `NA` を用いる必要が出てくる場合があります。あまり頻繁に起こることではないですが、注意が必要です。\
多いのは、**dplyr** 関数の `case_when()` を用いて新しい列を作成する場合などです。 [Cleaning data and core functions](#clean_case_when) のページで述べたように、この関数はデータフレーム内の全ての行に対して、ある基準（コードの右辺に書かれている条件）に合致するかどうかを評価し、新しい値（コードの左辺に書かれている値）を作成します。[右辺に書かれている値は、全ておなじクラスでないといけません。]{.ul}

```{r, eval=F}
linelist <- linelist %>% 
  
  # "age" 列から新しく "age_years" 列を作成する
  mutate(age_years = case_when(
    age_unit == "years"  ~ age,       # もし age が年で与えられていたら、そのままの値を返す
    age_unit == "months" ~ age/12,    # もし age が月で与えられていたら、12 で割る
    is.na(age_unit)      ~ age,       # もし age の UNIT が欠損であれば、years だと仮定する
    TRUE                 ~ NA_real_)) # 他のすべての場合には欠損とする
```

右辺に `NA` を持ってきたい場合は、以下に示している特殊な `NA` のうちのどれかを用いる必要があります。他の右辺の値が文字値の場合は "Missing" か、`NA_character_` を使用する必要があります。他の右辺が数値の場合は `NA_real_` を用いります。他の値がすべて日付や条件式であった場合 `NA` を用いることが出来ます。

-   `NA` ー日付や条件式 TRUE/FALSE において用いる
-   `NA_character_` ー文字値に用いる\
-   `NA_real_` ー数字値に用いる

繰り返しになりますが、新しい行を `case_when()` を用いて作成しようと[しない限り]{.ul}は、こうした例に出会うことはありません。より詳細について知りたい方は、[R documentation on NA](https://stat.ethz.ch/R-manual/R-devel/library/base/html/NA.html) を参考にしてください。

### `NULL` {.unnumbered}

他に R で用いられる値に、`NULL` があります。これは、条件が正でも誤でもないことを示しています。すなわち、値が定義されていない関数等によって返されます。一般的には、関数を書いたり、ある特定の条件において `NULL` を返すことを指示する [**shiny** app][Dashboards with Shiny] を書いたりする場合を除いて、NULL を値として指定することはありません。

Nullは `is.null()` を用いて評価され、`as.null()` を用いて変換されます。

`NULL` と `NA` の違いについては、[ブログのポスト](https://www.r-bloggers.com/2010/04/r-na-vs-null/) を見てください。

### `NaN` {.unnumbered}

取ることのできない値は、`NaN` で表されます。例えば、0 を 0 で割れ、と R に指示したような場合です。`is.nan()` を用いて評価することが出来、また、補足関数として`is.infinite()` や `is.finite()` が存在します。

### `Inf` {.unnumbered}

`Inf` は、例えばある値を 0 で割った場合など、無限大を表します。

これらの欠損値がどのように影響するかを簡単な例で示しましょう。例えば、`z <- c(1, 22, NA, Inf, NaN, 5)` で作成される `z` というベクターまたはコラムがあるとします。

一番大きな値を見つけるために `max()` という関数をこのコラムに適用することを考えます。`na.rm = TRUE` を用いることで、計算から `NA` を除くことが出来ます。しかし、`Inf` や `NaN` は残り、結果として `Inf` が返されます。これを解決するには、`[ ]` と `is.finite()` を用いて、すなわち `max(z[is.finite(z)])` とすることで、有限な値のみを含むサブセットを作成することが出来ます。

```{r, eval=F}
z <- c(1, 22, NA, Inf, NaN, 5)
max(z)                           # NA が返される
max(z, na.rm=T)                  # Inf が返される
max(z[is.finite(z)])             # 22 が返される
```

### 例 {.unnumbered}

+-----------------------------------------------------------------------------------------------------------------------+-----------------+
| R コマンド                                                                                                            | 出力            |
+=======================================================================================================================+=================+
| `5 / 0`                                                                                                               | `Inf`           |
+-----------------------------------------------------------------------------------------------------------------------+-----------------+
| `0 / 0`                                                                                                               | `NaN`           |
+-----------------------------------------------------------------------------------------------------------------------+-----------------+
| `5 / NA`                                                                                                              | `NA`            |
+-----------------------------------------------------------------------------------------------------------------------+-----------------+
| `5 / Inf |`0NA - 5`|`NAInf / 5`|`Infclass(NA)`| "logical"`class(NaN)`| "numeric"`class(Inf)`| "numeric"`class(NULL)\` | "NULL"          |
+-----------------------------------------------------------------------------------------------------------------------+-----------------+

"NAs introduced by coercion" はよくある警告メッセージです。数値のベクターに文字値を挿入しようとするなどの不正な操作を行った場合に起こります。

```{r}
as.numeric(c("10", "20", "thirty", "40"))
```

`NULL` はベクターにおいては無視されます。

```{r}
my_vector <- c(25, NA, 10, NULL)  # define
my_vector                         # print
```

ある一つの値のバリアンスを求めようとすると `NA` が返されます。

```{r}
var(22)
```

<!-- ======================================================= -->

## 便利な関数

以下では、R の **base** 関数で、欠損値を評価したり扱ったりする際に便利なものを示します。

### `is.na()` と `!is.na()` {.unnumbered}

`is.na()` は欠損値を特定する場合、または欠損でない値を特定する場合（`!` を一緒に用いります）に使います。どちらも理論値（`TRUE` or `FALSE`）が返されます。 返されたベクターに `sum()` を適用、例えば `sum(is.na(linelist$date_outcome))` とすることで、`TRUE` の数を計算することが出来ます。

```{r}
my_vector <- c(1, 4, 56, NA, 5, NA, 22)
is.na(my_vector)
!is.na(my_vector)
sum(is.na(my_vector))
```

### `na.omit()` {.unnumbered}

この関数をデータフレームに対して適用し、[全ての]{.ul}欠損値を含む行を除くことが出来ます。これもまた、R の **base** 関数です。\
ベクターに対して適用すると、`NA` を除くことが出来ます。例えば：

```{r}
na.omit(my_vector)
```

### `drop_na()` {.unnumbered}

[data cleaning pipeline][Cleaning data and core functions] の際に便利な **tidyr** の関数です。括弧内を空にして走らせると、欠損値を含む[全て]{.ul}の行を除くことが出来ます。括弧内で列の名前を指定することで、その列内の値を欠損している行を除くことが出来ます。列の指定には "tidyselect" を用いることもできます。

```{r, eval=F}
linelist %>% 
  drop_na(case_id, date_onset, age) # これらの列の値を欠損している行を除く
```

### `na.rm = TRUE` {.unnumbered}

`max()`、`min()`、`sum()` または、`mean()` などの数学関数を用いるときに `NA` が存在すると、`NA` が返されます。これは、欠損値があるという警告を知らせるためのデフォルトの挙動です。

計算から欠損値を除くことで、この警告を回避することが出来ます。そのためには、`na.rm = TRUE` （"na.rm" は "remove `NA`" の意）を一緒に用いります。

```{r}
my_vector <- c(1, 4, 56, NA, 5, NA, 22)

mean(my_vector)     

mean(my_vector, na.rm = TRUE)
```

<!-- ======================================================= -->

## データフレーム内の欠損を評価する

データフレーム `linelist` 内の欠損を評価し、視覚化するのに **naniar** というパッケージが使えます。

```{r}
# パッケージをインストールするもしくは読み込む
pacman::p_load(naniar)
```

### 欠損の数を数える {.unnumbered}

全ての欠損の値の割合を示すには `pct_miss()` を、数を示すには `n_miss()` を用いります。

```{r}
# すべてのデータフレーム内の欠損値の割合
pct_miss(linelist)
```

以下の 2 つの関数は、それぞれ、欠損値を含む行の割合、またはコンプリートケースの割合を返してくれます。`NA` は欠損を意味しますが、`""` や `" "` は欠損としてはカウントされないことに注意してください。

```{r}
# 欠損値を含む行の割合を示す
pct_miss_case(linelist)   # 数を示すには n_complete() を用いる
```

```{r}
# コンプリートケース（欠損のない行）の割合を示す  
pct_complete_case(linelist) # 数を示すには n_complete() を用いる
```

### 欠損値を視覚的に捉える {.unnumbered}

`gg_miss_var()` 関数を用いることで、それぞれの列における欠損値の数（もしくは割合）を示すことが出来ます。

-   プロットをグループごとに見たい場合は、`facet =` で列の名前（引用符にいれない）を指定することが出来ます\
-   デフォルトでは、割合ではなく数が表示されます。割合にしたい場合は `show_pct = TRUE` で指定します\
-   通常の `ggplot()` 通り、軸やタイトルのラベルを追加したい場合は `+ labs(...)` を用いて行うことが出来ます

```{r}
gg_miss_var(linelist, show_pct = TRUE)
```

以下では、データが `%>%` を用いて関数に渡されています。`facet =` を用いても、データを分けることが出来ます。

```{r}
linelist %>% 
  gg_miss_var(show_pct = TRUE, facet = outcome)
```

どの値が欠損しているかを示すために、`vis_miss()` を用いてデータフレームをヒートマップで表すことが出来ます。また `select()` を用いてある特定の列を指定することで、その列だけを示すこともできます。

```{r}
# データフレーム全体に対して欠損のヒートプロットを示す  
vis_miss(linelist)
```

### 欠損同士の関係性を探り、視覚化する {.unnumbered}

存在しないものをどうやって視覚化すればよいのでしょうか？デフォルトでは、`ggplot()` を使うと、欠損値は除いてプロットを作成してしまいます。

**naniar** の `geom_miss_point()` を用いれば解決します。2 つの列に対して散布図を作成するときに、ある一方の変数は存在し、片方の変数は欠損である場合には、欠損値をその列の最小値よりもさらに 10% 小さな値に変換し、違う色で散布図上に示してくれます。

以下に示している散布図では、赤いドットはある一方の変数は存在しているが片方の変数が欠損している場合を示しています。これによって欠損していない値に対する欠損している値の分布を視覚的に確認することが出来ます。

```{r}
ggplot(
  data = linelist,
  mapping = aes(x = age_years, y = temp)) +     
  geom_miss_point()
```

[別の列によって層別化した]{.ul}あとに欠損を評価したい場合は、`gg_miss_fct()` を使います。これは、[カテゴリ変数（または日付）の列ごとに]{.ul}データフレームの欠損の割合をヒートマップで示してくれます。

```{r}
gg_miss_fct(linelist, age_cat5)
```

この関数を日付ごとにデータフレームを示すのに用いると、欠損が時系列を追うごとにどのように変化しているかを示すことも出来ます。

```{r}
gg_miss_fct(linelist, date_onset)
```

### "付随する"列 {.unnumbered}

ある一方の列の欠損を、もう片方の列の値ごとに示す別の方法として、**naniar** の作成する"付随する列"を用いるものがあります。`bind_shadow()` を用いると、全ての列に対して `NA` または not `NA` の 2 値変数を作成し、これらの新しい列を "\_NA" を末尾に付けた新しい列として元のデータセットに結合してくれます。すなわち、データセットの列は 2 倍になります。

```{r}
shadowed_linelist <- linelist %>% 
  bind_shadow()

names(shadowed_linelist)
```

これらの"付随する列"は、他のどの列に対してでも、欠損している値の割合をプロットするのに使えます。

例えば、以下のプロットでは、`date_hospitalisation` 列の値ごとに、`days_onset_hosp` 列（発症してから入院までの日数）における欠損の割合を示しています。x 軸の列の密度をプロットしており、興味のある付随する列によって層別化（`color =`）していることに注意してください。x 軸が数値もしくは日付の列である場合、このプロットはうまく行きます。

```{r, message = F}
ggplot(data = shadowed_linelist,          # 付随する列を含むデータフレーム
  mapping = aes(x = date_hospitalisation, # 数値もしくは日付の列
                colour = age_years_NA)) + # 興味のある付随する列
  geom_density()                          # 密度曲線をプロットする
```

以下に示すように、統計量のサマリを層別化して示すのにも"付随する列"を使用することが出来ます。

```{r}
linelist %>%
  bind_shadow() %>%                # "付随する列"を作成する
  group_by(date_outcome_NA) %>%    # 層別化に用いる"付随する列"を指定する
  summarise(across(
    .cols = age_years,             # 統計量を示したい変数を指定する
    .fns = list("mean" = mean,     # 興味のある統計量を指定する
                "sd" = sd,
                "var" = var,
                "min" = min,
                "max" = max),  
    na.rm = TRUE))                 # 統計量の計算に用いるその他のコマンド
```

以下に、列の欠損値の割合を時系列ごとに示す他の方法を示します。以下の方法では、**naniar** は[使用しません]{.ul}。以下の例は、週ごとの観測値の欠損の割合を示しています。

1)  データを、興味のある単位時間（日、週、など）でまとめ、`NA`（そしてその他興味のある値）を含む観測値の割合を計算します\
2)  `ggplot()` を用いて、欠損の割合をラインとしてプロットします

以下では、ラインリストを用いて、まず週ごとの値を新しい列として加え、値が欠損している週ごとの記録の割合を計算しています（7 に置換の割合を計算したい場合は、以下のスクリプトとは少し異なります）。

```{r}
outcome_missing <- linelist %>%
  mutate(week = lubridate::floor_date(date_onset, "week")) %>%   # 新しく week の列を作成する
  group_by(week) %>%                                             # 行を、week ごとにグルーピングする
  summarise(                                                     # それぞれの week ごとにまとめる
    n_obs = n(),                                                  # 観測値の数
    
    outcome_missing = sum(is.na(outcome) | outcome == ""),        # 欠損を含む観測値の数
    outcome_p_miss  = outcome_missing / n_obs,                    # 欠損を含む観測値の割合
  
    outcome_dead    = sum(outcome == "Death", na.rm=T),           # 死亡例の観測値の数
    outcome_p_dead  = outcome_dead / n_obs) %>%                   # 死亡例の観測地の割合
  
  tidyr::pivot_longer(-week, names_to = "statistic") %>%         # ggplot のために week を除くすべての列をロング形式にピボットする
  filter(stringr::str_detect(statistic, "_p_"))                  # 割合を示す値だけを残す
```

このデータを用いて、週ごとに欠損の割合をラインで示します。**ggplot2** というプロットのためのパッケージについてあまり詳しくない場合は、[ggplot basics] のページを参考にしてください。

```{r, message=F, warning=F}
ggplot(data = outcome_missing)+
    geom_line(
      mapping = aes(x = week, y = value, group = statistic, color = statistic),
      size = 2,
      stat = "identity")+
    labs(title = "Weekly outcomes",
         x = "Week",
         y = "Proportion of weekly records") + 
     scale_color_discrete(
       name = "",
       labels = c("Died", "Missing outcome"))+
    scale_y_continuous(breaks = c(seq(0,1,0.1)))+
  theme_minimal()+
  theme(legend.position = "bottom")
```

<!-- ======================================================= -->

## Using data with missing values

### Filter out rows with missing values {.unnumbered}

To quickly remove rows with missing values, use the **dplyr** function `drop_na()`.

The original `linelist` has `nrow(linelist)` rows. The adjusted number of rows is shown below:

```{r}
linelist %>% 
  drop_na() %>%     # remove rows with ANY missing values
  nrow()
```

You can specify to drop rows with missingness in certain columns:

```{r}
linelist %>% 
  drop_na(date_onset) %>% # remove rows missing date_onset 
  nrow()
```

You can list columns one after the other, or use ["tidyselect" helper functions](#clean_tidyselect):

```{r}
linelist %>% 
  drop_na(contains("date")) %>% # remove rows missing values in any "date" column 
  nrow()
```

<!-- ======================================================= -->

### Handling `NA` in `ggplot()` {.unnumbered}

It is often wise to report the number of values excluded from a plot in a caption. Below is an example:

In `ggplot()`, you can add `labs()` and within it a `caption =`. In the caption, you can use `str_glue()` from **stringr** package to paste values together into a sentence dynamically so they will adjust to the data. An example is below:

-   Note the use of `\n` for a new line.\
-   Note that if multiple column would contribute to values not being plotted (e.g. age or sex if those are reflected in the plot), then you must filter on those columns as well to correctly calculate the number not shown.

```{r, eval=F}
labs(
  title = "",
  y = "",
  x = "",
  caption  = stringr::str_glue(
  "n = {nrow(central_data)} from Central Hospital;
  {nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown."))  
```

Sometimes, it can be easier to save the string as an object in commands prior to the `ggplot()` command, and simply reference the named string object within the `str_glue()`.

<!-- ======================================================= -->

### `NA` in factors {.unnumbered}

If your column of interest is a factor, use `fct_explicit_na()` from the **forcats** package to convert `NA` values to a character value. See more detail in the [Factors] page. By default, the new value is "(Missing)" but this can be adjusted via the `na_level =` argument.

```{r}
pacman::p_load(forcats)   # load package

linelist <- linelist %>% 
  mutate(gender = fct_explicit_na(gender, na_level = "Missing"))

levels(linelist$gender)
```

<!-- ======================================================= -->

## Imputation

Sometimes, when analyzing your data, it will be important to "fill in the gaps" and impute missing data While you can always simply analyze a dataset after removing all missing values, this can cause problems in many ways. Here are two examples:

1)  By removing all observations with missing values or variables with a large amount of missing data, you might reduce your power or ability to do some types of analysis. For example, as we discovered earlier, only a small fraction of the observations in our linelist dataset have no missing data across all of our variables. If we removed the majority of our dataset we'd be losing a lot of information! And, most of our variables have some amount of missing data--for most analysis it's probably not reasonable to drop every variable that has a lot of missing data either.

2)  Depending on why your data is missing, analysis of only non-missing data might lead to biased or misleading results. For example, as we learned earlier we are missing data for some patients about whether they've had some important symptoms like fever or cough. But, as one possibility, maybe that information wasn't recorded for people that just obviously weren't very sick. In that case, if we just removed these observations we'd be excluding some of the healthiest people in our dataset and that might really bias any results.

It's important to think about why your data might be missing in addition to seeing how much is missing. Doing this can help you decide how important it might be to impute missing data, and also which method of imputing missing data might be best in your situation.

### Types of missing data {.unnumbered}

Here are three general types of missing data:

1)  **Missing Completely at Random** (MCAR). This means that there is no relationship between the probability of data being missing and any of the other variables in your data. The probability of being missing is the same for all cases This is a rare situation. But, if you have strong reason to believe your data is MCAR analyzing only non-missing data without imputing won't bias your results (although you may lose some power). [TODO: consider discussing statistical tests for MCAR]

2)  **Missing at Random** (MAR). This name is actually a bit misleading as MAR means that your data is missing in a systematic, predictable way based on the other information you have. For example, maybe every observation in our dataset with a missing value for fever was actually not recorded because every patient with chills and and aches was just assumed to have a fever so their temperature was never taken. If true, we could easily predict that every missing observation with chills and aches has a fever as well and use this information to impute our missing data. In practice, this is more of a spectrum. Maybe if a patient had both chills and aches they were more likely to have a fever as well if they didn't have their temperature taken, but not always. This is still predictable even if it isn't perfectly predictable. This is a common type of missing data

3)  **Missing not at Random** (MNAR). Sometimes, this is also called **Not Missing at Random** (NMAR). This assumes that the probability of a value being missing is NOT systematic or predictable using the other information we have but also isn't missing randomly. In this situation data is missing for unknown reasons or for reasons you don't have any information about. For example, in our dataset maybe information on age is missing because some very elderly patients either don't know or refuse to say how old they are. In this situation, missing data on age is related to the value itself (and thus isn't random) and isn't predictable based on the other information we have. MNAR is complex and often the best way of dealing with this is to try to collect more data or information about why the data is missing rather than attempt to impute it.

In general, imputing MCAR data is often fairly simple, while MNAR is very challenging if not impossible. Many of the common data imputation methods assume MAR.

### Useful packages {.unnumbered}

Some useful packages for imputing missing data are Mmisc, missForest (which uses random forests to impute missing data), and mice (Multivariate Imputation by Chained Equations). For this section we'll just use the mice package, which implements a variety of techniques. The maintainer of the mice package has published an online book about imputing missing data that goes into more detail here (<https://stefvanbuuren.name/fimd/>).

Here is the code to load the mice package:

```{r}
pacman::p_load(mice)
```

### Mean Imputation {.unnumbered}

Sometimes if you are doing a simple analysis or you have strong reason to think you can assume MCAR, you can simply set missing numerical values to the mean of that variable. Perhaps we can assume that missing temperature measurements in our dataset were either MCAR or were just normal values. Here is the code to create a new variable that replaces missing temperature values with the mean temperature value in our dataset. However, in many situations replacing data with the mean can lead to bias, so be careful.

```{r}
linelist <- linelist %>%
  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))
```

You could also do a similar process for replacing categorical data with a specific value. For our dataset, imagine you knew that all observations with a missing value for their outcome (which can be "Death" or "Recover") were actually people that died (note: this is not actually true for this dataset):

```{r}
linelist <- linelist %>%
  mutate(outcome_replace_na_with_death = replace_na(outcome, "Death"))
```

### Regression imputation {.unnumbered}

A somewhat more advanced method is to use some sort of statistical model to predict what a missing value is likely to be and replace it with the predicted value. Here is an example of creating predicted values for all the observations where temperature is missing, but age and fever are not, using simple linear regression using fever status and age in years as predictors. In practice you'd want to use a better model than this sort of simple approach.

```{r, warning=F, message=F}
simple_temperature_model_fit <- lm(temp ~ fever + age_years, data = linelist)

#using our simple temperature model to predict values just for the observations where temp is missing
predictions_for_missing_temps <- predict(simple_temperature_model_fit,
                                        newdata = linelist %>% filter(is.na(temp))) 
```

Or, using the same modeling approach through the mice package to create imputed values for the missing temperature observations:

```{r}
model_dataset <- linelist %>%
  select(temp, fever, age_years)  

temp_imputed <- mice(model_dataset,
                            method = "norm.predict",
                            seed = 1,
                            m = 1,
                            print = F)

temp_imputed_values <- temp_imputed$imp$temp

```

This is the same type of approach by some more advanced methods like using the missForest package to replace missing data with predicted values. In that case, the prediction model is a random forest instead of a linear regression. You can use other types of models to do this as well. However, while this approach works well under MCAR you should be a bit careful if you believe MAR or MNAR more accurately describes your situation. The quality of your imputation will depend on how good your prediction model is and even with a very good model the variability of your imputed data may be underestimated.

### LOCF and BOCF {.unnumbered}

Last observation carried forward (LOCF) and baseline observation carried forward (BOCF) are imputation methods for time series/longitudinal data. The idea is to take the previous observed value as a replacement for the missing data. When multiple values are missing in succession, the method searches for the last observed value.

The `fill()` function from the **tidyr** package can be used for both LOCF and BOCF imputation (however, other packages such as **HMISC**, **zoo**, and **data.table** also include methods for doing this). To show the `fill()` syntax we'll make up a simple time series dataset containing the number of cases of a disease for each quarter of the years 2000 and 2001. However, the year value for subsequent quarters after Q1 are missing so we'll need to impute them. The `fill()` junction is also demonstrated in the [Pivoting data] page.

```{r}
#creating our simple dataset
disease <- tibble::tribble(
  ~quarter, ~year, ~cases,
  "Q1",    2000,    66013,
  "Q2",      NA,    69182,
  "Q3",      NA,    53175,
  "Q4",      NA,    21001,
  "Q1",    2001,    46036,
  "Q2",      NA,    58842,
  "Q3",      NA,    44568,
  "Q4",      NA,    50197)

#imputing the missing year values:
disease %>% fill(year)

```

Note: make sure your data are sorted correctly before using the `fill()` function. `fill()` defaults to filling "down" but you can also impute values in different directions by changing the `.direction` parameter. We can make a similar dataset where the year value is recorded only at the end of the year and missing for earlier quarters:

```{r}
#creating our slightly different dataset
disease <- tibble::tribble(
  ~quarter, ~year, ~cases,
  "Q1",      NA,    66013,
  "Q2",      NA,    69182,
  "Q3",      NA,    53175,
  "Q4",    2000,    21001,
  "Q1",      NA,    46036,
  "Q2",      NA,    58842,
  "Q3",      NA,    44568,
  "Q4",    2001,    50197)

#imputing the missing year values in the "up" direction:
disease %>% fill(year, .direction = "up")

```

In this example, LOCF and BOCF are clearly the right things to do, but in more complicated situations it may be harder to decide if these methods are appropriate. For example, you may have missing laboratory values for a hospital patient after the first day. Sometimes, this can mean the lab values didn't change...but it could also mean the patient recovered and their values would be very different after the first day! Use these methods with caution.

### Multiple Imputation {.unnumbered}

The online book we mentioned earlier by the author of the mice package (<https://stefvanbuuren.name/fimd/>) contains a detailed explanation of multiple imputation and why you'd want to use it. But, here is a basic explanation of the method:

When you do multiple imputation, you create multiple datasets with the missing values imputed to plausible data values (depending on your research data you might want to create more or less of these imputed datasets, but the mice package sets the default number to 5). The difference is that rather than a single, specific value each imputed value is drawn from an estimated distribution (so it includes some randomness). As a result, each of these datasets will have slightly different different imputed values (however, the non-missing data will be the same in each of these imputed datasets). You still use some sort of predictive model to do the imputation in each of these new datasets (mice has many options for prediction methods including *Predictive Mean Matching*, *logistic regression*, and *random forest*) but the mice package can take care of many of the modeling details.

Then, once you have created these new imputed datasets, you can apply then apply whatever statistical model or analysis you were planning to do for each of these new imputed datasets and pool the results of these models together. This works very well to reduce bias in both MCAR and many MAR settings and often results in more accurate standard error estimates.

Here is an example of applying the Multiple Imputation process to predict temperature in our linelist dataset using a age and fever status (our simplified model_dataset from above):

```{r}
# imputing missing values for all variables in our model_dataset, and creating 10 new imputed datasets
multiple_imputation = mice(
  model_dataset,
  seed = 1,
  m = 10,
  print = FALSE) 

model_fit <- with(multiple_imputation, lm(temp ~ age_years + fever))

base::summary(mice::pool(model_fit))
```

Here we used the mice default method of imputation, which is Predictive Mean Matching. We then used these imputed datasets to separately estimate and then pool results from simple linear regressions on each of these datasets. There are many details we've glossed over and many settings you can adjust during the Multiple Imputation process while using the mice package. For example, you won't always have numerical data and might need to use other imputation methods (you can still use the mice package for many other types of data and methods). But, for a more robust analysis when missing data is a significant concern, Multiple Imputation is good solution that isn't always much more work than doing a complete case analysis.

<!-- ======================================================= -->

## Resources

Vignette on the [naniar package](https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html)

Gallery of [missing value visualizations](https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html)

[Online book](https://stefvanbuuren.name/fimd/) about multiple imputation in R by the maintainer of the **mice** package
